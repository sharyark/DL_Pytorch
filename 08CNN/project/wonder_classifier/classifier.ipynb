{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20017dd0-59c9-4175-a238-40fc5a27b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef79fb0a",
   "metadata": {},
   "source": [
    "# üî• Check if GPU is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4408f8c-20dd-46ca-b263-b749596f1899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b62d7",
   "metadata": {},
   "source": [
    "## üìå 1Ô∏è‚É£ Define Transformations (Resizing + Normalization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b7ac9-701d-441c-bbc6-224dcb0bb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images\n",
    "    transforms.ToTensor(),  # Convert images to tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize (0-1 ‚Üí -1 to 1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38d53f8",
   "metadata": {},
   "source": [
    "## üìå 2Ô∏è‚É£ Load Dataset from Directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0689bd1-c346-429a-a0a0-2284a7539439",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(root=\"./WondersofWorld\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0dd1366e-9636-406f-90eb-8d1e91b90ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img,label = dataset[3800]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f80ffae1-28fe-4c04-bcd0-97b2585e78f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'burj_khalifa': 0, 'chichen_itza': 1, 'christ_the_reedemer': 2, 'eiffel_tower': 3, 'great_wall_of_china': 4, 'machu_pichu': 5, 'pyramids_of_giza': 6, 'roman_colosseum': 7, 'statue_of_liberty': 8, 'stonehenge': 9, 'taj_mahal': 10, 'venezuela_angel_falls': 11}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3846"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset.class_to_idx)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5e6bddd-ef3d-434d-a8dc-58d60d6707c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ 80% Training, 20% Validation Split\n",
    "train_size = int(0.8 * len(dataset))  # 80% data for training\n",
    "val_size = len(dataset) - train_size  # 20% data for validation\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04cd556f-03d8-41b7-b608-2e5ebe5f4e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7b96ead37440>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509149b3",
   "metadata": {},
   "source": [
    "## üìå 3Ô∏è‚É£ Create DataLoaders (With Shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fc3856-c7cb-4983-b601-bfe63effdfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # Same as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c402a0d5-3b23-4695-a4f1-ce582ca0a319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 3076\n",
      "Validation samples: 770\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {train_size}\")\n",
    "print(f\"Validation samples: {val_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752f0ee5",
   "metadata": {},
   "source": [
    "## üìå 4Ô∏è‚É£ Define CNN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f824e-4810-4b58-a243-ceb8c13c2b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=12):  # 12 classes\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 256)  # Adjusted for 224x224 input\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)  # Prevent overfitting\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31921b00",
   "metadata": {},
   "source": [
    "## üìå 5Ô∏è‚É£ Initialize Model and Move to GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c48d759-364f-4e84-9cd4-6b534e1363db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(num_classes=12).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c4116c",
   "metadata": {},
   "source": [
    "## üìå 6Ô∏è‚É£ Define Loss & Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7ced1-ca93-4c4a-9287-bb279ee1a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # Multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam Optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1a96de",
   "metadata": {},
   "source": [
    "## üìå 7Ô∏è‚É£ Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a2e2d-d4f7-4ac6-9bb8-bec6de8eeadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 2.1270, Train Accuracy: 0.2477\n",
      "Epoch 2/2, Loss: 1.7087, Train Accuracy: 0.4119\n"
     ]
    }
   ],
   "source": [
    "epochs = 2  # Change as needed\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd307a0",
   "metadata": {},
   "source": [
    "## üìå 8Ô∏è‚É£ Validation Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5adff5a-1fc5-4af0-8521-397cebc41e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.5811, Validation Accuracy: 0.4818\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "val_loss = 0.0\n",
    "\n",
    "with torch.no_grad():  # No gradients for validation\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "val_accuracy = correct / total\n",
    "print(f\"Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da40129-14d9-40ee-bac0-81a7523511fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
